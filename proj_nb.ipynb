{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'client' is not defined\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, progress\n",
    "import dask.array as da\n",
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler\n",
    "from dask_ml import cluster, decomposition, linear_model, metrics, xgboost\n",
    "from dask_ml.impute import SimpleImputer\n",
    "from dask_ml.model_selection import train_test_split, KFold\n",
    "from dask_ml.preprocessing import OneHotEncoder \n",
    "from zipfile import ZipFile \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def cat_features(dataframe):\n",
    "    td = pd.DataFrame({'a': [1,2,3], 'b': [1.0, 2.0, 3.0]})\n",
    "    return filter(lambda x: not(dataframe[x].dtype in [td['a'].dtype, td['b'].dtype]), list(dataframe))\n",
    "\n",
    "#close existing dask connection if it exists and open a new one\n",
    "try:\n",
    "    if client is not None:\n",
    "        client.close()\n",
    "        print(\"closed existing connection, \",client)       \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:43831\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:43831' processes=2 cores=4>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get new connection\n",
    "client = Client(n_workers=2, threads_per_worker=2, memory_limit='8GB')\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dataset:  2097149\n",
      "Number of Columns:  27\n"
     ]
    }
   ],
   "source": [
    "# Declare the dtypes of the file to be more efficient when reading in \n",
    "feat_types = {'Dst Port': np.float64, 'Protocol': np.int64, 'Timestamp': str, \n",
    "              'Flow Duration': np.int64, 'Tot Fwd Pkts': np.int64, 'Tot Bwd Pkts': np.int64, \n",
    "              'TotLen Fwd Pkts': np.int64, 'TotLen Bwd Pkts': np.int64, 'Fwd Pkt Len Max': np.int64, \n",
    "              'Fwd Pkt Len Min': np.int64, 'Fwd Pkt Len Mean': np.float64, 'Fwd Pkt Len Std': np.float64, \n",
    "              'Bwd Pkt Len Max': np.int64, 'Bwd Pkt Len Min': np.int64, 'Bwd Pkt Len Mean': np.float64, \n",
    "              'Bwd Pkt Len Std': str, 'Flow Byts/s': str, 'Flow Pkts/s': np.float64, \n",
    "              'Flow IAT Mean': np.float64, 'Flow IAT Std': np.float64, 'Flow IAT Max': np.int64, \n",
    "              'Flow IAT Min': np.int64, 'Fwd IAT Tot': np.int64, 'Fwd IAT Mean': np.float64, \n",
    "              'Fwd IAT Std': np.float64, 'Fwd IAT Max': np.int64, 'Fwd IAT Min': np.int64, \n",
    "              'Bwd IAT Tot': np.int64, 'Bwd IAT Mean': np.float64, 'Bwd IAT Std': np.float64, \n",
    "              'Bwd IAT Max': np.int64, 'Bwd IAT Min': np.int64, 'Fwd PSH Flags': np.int64, \n",
    "              'Bwd PSH Flags': np.int64, 'Fwd URG Flags': np.int64, 'Bwd URG Flags': np.int64, \n",
    "              'Fwd Header Len': np.int64, 'Bwd Header Len': np.int64, 'Fwd Pkts/s': np.float64, \n",
    "              'Bwd Pkts/s': np.float64, 'Pkt Len Min': np.int64, 'Pkt Len Max': np.int64, \n",
    "              'Pkt Len Mean': np.float64, 'Pkt Len Std': np.float64, 'Pkt Len Var': np.float64, \n",
    "              'FIN Flag Cnt': np.int64, 'SYN Flag Cnt': np.int64, 'RST Flag Cnt': np.int64, \n",
    "              'PSH Flag Cnt': np.int64, 'ACK Flag Cnt': np.int64, 'URG Flag Cnt': np.int64, \n",
    "              'CWE Flag Count': np.int64, 'ECE Flag Cnt': np.int64, 'Down/Up Ratio': np.int64, \n",
    "              'Pkt Size Avg': np.float64, 'Fwd Seg Size Avg': np.float64, 'Bwd Seg Size Avg': np.float64, \n",
    "              'Fwd Byts/b Avg': np.int64, 'Fwd Pkts/b Avg': np.int64, 'Fwd Blk Rate Avg': np.int64, \n",
    "              'Bwd Byts/b Avg': np.int64, 'Bwd Pkts/b Avg': np.int64, 'Bwd Blk Rate Avg': np.int64, \n",
    "              'Subflow Fwd Pkts': np.int64, 'Subflow Fwd Byts': np.int64, 'Subflow Bwd Pkts': np.int64, \n",
    "              'Subflow Bwd Byts': np.int64, 'Init Fwd Win Byts': np.int64, 'Init Bwd Win Byts': np.int64, \n",
    "              'Fwd Act Data Pkts': np.int64, 'Fwd Seg Size Min': np.int64, 'Active Mean': np.float64, \n",
    "              'Active Std': np.float64, 'Active Max': np.int64, 'Active Min': np.int64, \n",
    "              'Idle Mean': np.float64, 'Idle Std': np.float64, 'Idle Max': np.int64,\n",
    "              'Idle Min': np.int64, 'Label': str}\n",
    "\n",
    "feat_types_check = {'Dst Port': float, 'Protocol': int, 'Timestamp': str, \n",
    "              'Flow Duration': int, 'Tot Fwd Pkts': int, 'Tot Bwd Pkts': int, \n",
    "              'TotLen Fwd Pkts': int, 'TotLen Bwd Pkts': int, \n",
    "              'Flow Pkts/s': float,  'Fwd PSH Flags': int, \n",
    "              'Bwd PSH Flags': int, 'Fwd URG Flags': int, 'Bwd URG Flags': int, \n",
    "              'Fwd Pkts/s': float, \n",
    "              'Bwd Pkts/s': float,\n",
    "              'FIN Flag Cnt': int, 'SYN Flag Cnt': int, 'RST Flag Cnt': int, \n",
    "              'PSH Flag Cnt': int, 'ACK Flag Cnt': int, 'URG Flag Cnt': int, \n",
    "              'CWE Flag Count': int, 'ECE Flag Cnt': int, \n",
    "              'Subflow Fwd Pkts': int, 'Subflow Fwd Byts': int, 'Subflow Bwd Pkts': int, \n",
    "              'Subflow Bwd Byts': int, 'Label': str}\n",
    "\n",
    "feature_cols = ['Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', \n",
    "                'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts',\n",
    "                'TotLen Bwd Pkts', 'Flow Pkts/s', \n",
    "                'Flow IAT Mean', 'Fwd PSH Flags', 'Bwd PSH Flags', \n",
    "                'Fwd URG Flags','Bwd URG Flags', 'FIN Flag Cnt', \n",
    "                'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', \n",
    "                'ACK Flag Cnt', 'URG Flag Cnt','CWE Flag Count', \n",
    "                'ECE Flag Cnt', 'Subflow Fwd Pkts','Subflow Fwd Byts', \n",
    "                'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Label']\n",
    "# print(len(feat_types_check))\n",
    "# print(feature_cols[18])\n",
    "df = dd.read_csv('cic_data/23_02_2018.csv', usecols=feature_cols, low_memory=False)\n",
    "df_2 = dd.read_csv('cic_data/16_02_2018_fixeddata.csv', usecols=feature_cols, low_memory=False)\n",
    "df = df.append(df_2)\n",
    "print(\"Length of Dataset: \", len(df))\n",
    "print(\"Number of Columns: \", len(df.columns))\n",
    "# print(\"Categorical Features: \", list(cat_features(df)))\n",
    "# Files in the zipped folder:\n",
    "# 23_02_2018.csv, 20_02_2018.csv, 16_02_2018.csv, 02_03_2018.csv\n",
    "# with ZipFile('cic_data.zip') as zipped:\n",
    "#     df = dd.from_pandas(pd.read_csv(zipped.open('23_02_2018.csv'), usecols=feature_cols), npartitions=2)\n",
    "#     df = df.append(pd.read_csv(zipped.open('16_02_2018.csv'), usecols=feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['Dst Port', 'Protocol', 'Flow Duration', \n",
    "                'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts',\n",
    "                'TotLen Bwd Pkts', 'Flow Byts/s', 'Flow Pkts/s', \n",
    "                'Flow IAT Mean', 'Fwd PSH Flags', 'Bwd PSH Flags', \n",
    "                'Fwd URG Flags','Bwd URG Flags', 'FIN Flag Cnt', \n",
    "                'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', \n",
    "                'ACK Flag Cnt', 'URG Flag Cnt','CWE Flag Count', \n",
    "                'ECE Flag Cnt', 'Subflow Fwd Pkts','Subflow Fwd Byts', \n",
    "                'Subflow Bwd Pkts', 'Subflow Bwd Byts']\n",
    "df['Target'] = 0 \n",
    "df['Target'] = df['Target'].mask(df['Label'] != 'Benign', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col in feat_types_check.keys():\n",
    "        df[col] = df[col].astype(feat_types_check[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Target']\n",
    "# drop_cols = [col for col in df.columns if col not in x_cols]\n",
    "x = df.drop(['Label', 'Target', 'Timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that takes X, Y and gives you a train test split\n",
    "def doTrainTestSplit(X,Y):\n",
    "    #breakpoint()\n",
    "    #look at dask dataframes\n",
    "#     display(X.head())\n",
    "#     display(Y.head())\n",
    "   \n",
    "    #get splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=.3)\n",
    "#     display(X_train.compute())\n",
    "#     display(y_train.compute())\n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = doTrainTestSplit(x,y)\n",
    "x_train = x_train.to_dask_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = imp.fit_transform(x_train)\n",
    "# x_test = imp.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Worker process 7559 was killed by signal 6\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker process 7557 was killed by signal 6\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgboost.XGBClassifier(n_estimators=5)\n",
    "xgb_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondaa9d3b5d186f149eeb25c9be13305630c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
