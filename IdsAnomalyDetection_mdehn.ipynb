{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, progress\n",
    "import dask.array as da\n",
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask_ml\n",
    "#prefs\n",
    "pd.set_option('max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close existing dask connection if it exists and open a new one\n",
    "try:\n",
    "    if client is not None:\n",
    "        client.close()\n",
    "        print(\"closed existing connection, \",client)       \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get new connection\n",
    "client = Client(n_workers=2, threads_per_worker=2, memory_limit='8GB')\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get stock data\n",
    "data = dd.read_csv(\"ids-data/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\")\n",
    "\n",
    "#display(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp'] = dd.to_datetime(data.Timestamp, format='%d/%m/%Y %H:%M:%S').astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data = data.loc[:, 'Dst Port':'Idle Min']\n",
    "too_big = (tmp_data > np.finfo(np.float32).max)\n",
    "too_big = (too_big).any()\n",
    "with pd.option_context('max_rows', None):\n",
    "    display(too_big.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get labels for decision tree presentation, note the use of unique later \n",
    "labels = data['Label']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which features we want to include in our analysis\n",
    "\n",
    "possible_features = 'Dst Port\tProtocol\tTimestamp\tFlow Duration\tTot Fwd Pkts\tTot Bwd Pkts\tTotLen Fwd Pkts\tTotLen Bwd Pkts\tFwd Pkt Len Max\tFwd Pkt Len Min\tFwd Pkt Len Mean\tFwd Pkt Len Std\tBwd Pkt Len Max\tBwd Pkt Len Min\tBwd Pkt Len Mean\tBwd Pkt Len Std\tFlow Byts/s\tFlow Pkts/s\tFlow IAT Mean\tFlow IAT Std\tFlow IAT Max\tFlow IAT Min\tFwd IAT Tot\tFwd IAT Mean\tFwd IAT Std\tFwd IAT Max\tFwd IAT Min\tBwd IAT Tot\tBwd IAT Mean\tBwd IAT Std\tBwd IAT Max\tBwd IAT Min\tFwd PSH Flags\tBwd PSH Flags\tFwd URG Flags\tBwd URG Flags\tFwd Header Len\tBwd Header Len\tFwd Pkts/s\tBwd Pkts/s\tPkt Len Min\tPkt Len Max\tPkt Len Mean\tPkt Len Std\tPkt Len Var\tFIN Flag Cnt\tSYN Flag Cnt\tRST Flag Cnt\tPSH Flag Cnt\tACK Flag Cnt\tURG Flag Cnt\tCWE Flag Count\tECE Flag Cnt\tDown/Up Ratio\tPkt Size Avg\tFwd Seg Size Avg\tBwd Seg Size Avg\tFwd Byts/b Avg\tFwd Pkts/b Avg\tFwd Blk Rate Avg\tBwd Byts/b Avg\tBwd Pkts/b Avg\tBwd Blk Rate Avg\tSubflow Fwd Pkts\tSubflow Fwd Byts\tSubflow Bwd Pkts\tSubflow Bwd Byts\tInit Fwd Win Byts\tInit Bwd Win Byts\tFwd Act Data Pkts\tFwd Seg Size Min\tActive Mean\tActive Std\tActive Max\tActive Min\tIdle Mean\tIdle Std\tIdle Max\tIdle Min'.split('\\t')\n",
    "\n",
    "exclude_features = ('Timestamp', 'Flow Byts/s', 'Flow Pkts/s')\n",
    "\n",
    "features = [f for f in possible_features if f not in exclude_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataframe of just features\n",
    "X = data.loc[:, features]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup plot\n",
    "import matplotlib.pyplot as plt\n",
    "print(plt.rcParams.get('figure.figsize'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup figure size\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 20\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import KFold as K\n",
    "from dask_ml.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "#fit and predict\n",
    "clf.fit(X_train, y_train)\n",
    "plot_confusion_matrix(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def doKFolds(X,Y):\n",
    "    \n",
    "    #look at dask dataframes\n",
    "    display(X.head())\n",
    "    display(Y.head())\n",
    "\n",
    "    #create KFold object\n",
    "    c = K()\n",
    "    #breakpoint()\n",
    "    #split on dask arrays, doesn't work on dataframes yet\n",
    "    gen = c.split(X.to_dask_array(lengths=True),Y.to_dask_array(lengths=True))\n",
    "\n",
    "    #inspect generator\n",
    "    print(gen)\n",
    "    display(type(gen))\n",
    "    \n",
    "    #call generator\n",
    "    for train,test in gen:\n",
    "        print(\"train = \",train.compute())\n",
    "        print(\"test = \",test.compute())\n",
    "        print(\"x train = \",X.loc[train])\n",
    "        got = X.loc[train.compute()]\n",
    "        display(got.head())\n",
    "        #print(got.compute())\n",
    "        clf.fit(got,got)\n",
    "\n",
    "        \n",
    "doKFolds(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "#time with just pandas\n",
    "with joblib.parallel_backend('threading'):\n",
    "     clf.fit(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "#time with dask\n",
    "with joblib.parallel_backend('dask'):\n",
    "     clf.fit(X, Y)\n",
    "\n",
    "\n",
    "#clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "#time with dask, even if you set threaing it's still a dask dataframe so it's produced via dasks engine\n",
    "with joblib.parallel_backend('threading'):\n",
    "     clf.fit(X, Y)\n",
    "\n",
    "\n",
    "#clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cache results note you have to assign in X and Y\n",
    "X = client.persist(X)\n",
    "Y = client.persist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "#time with dask after cache\n",
    "with joblib.parallel_backend('dask'):\n",
    "     clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "#time with just pandas once X and Y are cached\n",
    "with joblib.parallel_backend('threading'):\n",
    "     clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = tree.plot_tree(clf,feature_names=features,class_names=labels.astype(str),rounded=True,filled=True) \n",
    "x = tree.plot_tree(clf,rounded=True,filled=True,class_names=sorted,feature_names=features) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}