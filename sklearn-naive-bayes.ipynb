{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrusion detection system - Naive Bayes Classifier\n",
    "\n",
    "This notebook uses the Guassian Naive Bayes Classifier for detection of network attacks on a simulation network capture dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup\n",
    "\n",
    "This module cleans up some of the duplicate headers in the source files.  \n",
    "The data is then stored in the \"./cleaned/\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "for file in [\"Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "             ,\"Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "             ,\"Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "             ,\"Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "             ,\"Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "             ,\"Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "             ,\"Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "             ,\"Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "             ,\"Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\"]:\n",
    "    output_filepath=\"cleaned_files/\" + file\n",
    "    with open(file,\"r\") as inputfile, open(output_filepath,\"w\",newline=\"\") as outputfile:\n",
    "        csv_in = csv.reader(inputfile)\n",
    "        csv_out = csv.writer(outputfile)\n",
    "        title = next(csv_in)\n",
    "        csv_out.writerow(title)\n",
    "        for row in csv_in:\n",
    "            if row != title:\n",
    "                 csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframes from CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "              'Friday-16-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "               'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv']\n",
    "\n",
    "flow_df = pd.DataFrame()\n",
    "for file in filenames:\n",
    "    filepath = \"cleaned_files/\" + file\n",
    "    x_df = pd.read_csv(filepath)\n",
    "    flow_df = flow_df.append(other=x_df, ignore_index=True)\n",
    "\n",
    "feature_cols = ['Flow Duration', 'Tot Fwd Pkts',\n",
    "            'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max',\n",
    "            'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std',\n",
    "            'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean',\n",
    "            'Bwd Pkt Len Std', 'Flow IAT Mean',\n",
    "            'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot',\n",
    "            'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',\n",
    "            'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
    "            'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags',\n",
    "            'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
    "            'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean',\n",
    "            'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt',\n",
    "            'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt',\n",
    "            'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg',\n",
    "            'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg',\n",
    "            'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',\n",
    "            'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts',\n",
    "            'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts',\n",
    "            'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts',\n",
    "            'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',\n",
    "            'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min',\n",
    "               'Dst Port', 'Protocol']\n",
    "\n",
    "excluded_cols = ['Flow Byts/s', 'Flow Pkts/s', 'Timestamp']\n",
    "\n",
    "X = flow_df[feature_cols]\n",
    "\n",
    "y = flow_df['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and normalization\n",
    "\n",
    "The select K-Best classifier uses the ANOVA test to pick out the 10 best features from the vast set of 74 features.\n",
    "\n",
    "The min-max scaler normalizes all features between 0 and 1. This was done in order to improve K-NN performance, but it does improve the NB performance as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\prashant\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: UserWarning: Features [28 29 30 46 52 53 54 55 56 57] are constant.\n",
      "  UserWarning)\n",
      "c:\\users\\prashant\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "feature_selector = SelectKBest(f_classif, k=10)\n",
    "X =  feature_selector.fit_transform(X, y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_norm = scaler.transform(X)\n",
    "\n",
    "flow_df_norm = pd.DataFrame(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test Train Split\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(flow_df_norm, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE Oversampling\n",
    "\n",
    "This optional module will balance your data set to include equal amounts of all labels, using a oversampling technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Oversampler for dealing with imbalanced sets\n",
    "'''\n",
    "balance_data = False\n",
    "\n",
    "    \n",
    "if balance_data:\n",
    "    oversampler = SMOTE()\n",
    "    X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit train data into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "Naive Bayes Classifier\n",
    "'''\n",
    "gnb = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusion matrix\n",
    "\n",
    "The module does a decent job of predicting that a attack is happening, however it is prone to confuse between the types of attacks.\n",
    "\n",
    "There are also a large amount of false positive attacks, which lower the precision considerably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Confusion Matrix\n",
    "'''\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plot_confusion_matrix(gnb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print model metrics\n",
    "\n",
    "recall 0.9793341077792436  \n",
    "precision 0.7055214027761624  \n",
    "accuracy 0.8266663487749247  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Metrics\n",
    "'''\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "pred = pd.DataFrame(\n",
    "    [0 if d == 'Benign' else 1 for d in y_pred], columns=[\"obs\"])\n",
    "test = pd.DataFrame(\n",
    "    [0 if d == 'Benign' else 1 for d in y_test], columns=[\"obs\"])\n",
    "\n",
    "pred[\"obs\"] = pd.to_numeric(pred[\"obs\"])\n",
    "test[\"obs\"] = pd.to_numeric(test[\"obs\"])\n",
    "\n",
    "print(\"recall {}\".format(recall_score(test, pred)))\n",
    "print(\"precision {}\".format(precision_score(test, pred)))\n",
    "print(\"accuracy {}\".format(accuracy_score(test, pred)))\n",
    "\n",
    "print(\"count events {}\".format(test[\"obs\"].value_counts().to_dict()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
